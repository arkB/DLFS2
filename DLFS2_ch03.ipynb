{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLFS2_ch03.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkB/DLFS2/blob/master/DLFS2_ch03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RvzpKN87dGsb",
        "colab_type": "code",
        "outputId": "06a20521-d4fa-4eb0-e522-f5f4ee28c525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!cp -f ~/.gdfuse/default/config config\n",
        "!sed -i -e \"s/^root_folder=$/root_folder=1jJNYTm2oOyHuqn_4usJ4BMuaCE4BAVav/\" config\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse -config ./config -cc drive\n",
        "import os\n",
        "os.chdir('drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 110845 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "Clearing cache...done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-z5uWG5gFmmQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. word2vec\n",
        "\n",
        "2章では「**カウントベースの手法（コーパス中の各単語に対して、その単語の周囲の頻度をカウントし集計する手法）**」を学びました。\n",
        "\n",
        "3章では「カウントベースの手法」の問題点を示し、それに代わる「推論ベースの手法」を紹介します。\n",
        "\n",
        "「推論ベースの手法」とは、下の図のように周囲の単語（コンテクスト）が与えられたときに「？」に当てはまる単語を推測し答えを与えるための手法のことです。\n",
        "\n",
        "<img width=\"655.5\" alt=\"キャプチャ.PNG (21.5 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/9782ee68-f48c-42f4-b63d-0a170840ad5e.PNG\">\n",
        "\n",
        "具体的には、「推論ベースの手法」では、モデルを学習させてそのモデルにコンテキストを与えると「？」に当てはまる単語の出現確率を出力します。\n",
        "\n",
        "今回ここではモデルとして「ニューラルネットワーク」を用います。\n",
        "\n",
        "ちなみに、「推論ベースの手法」も「カウントベースの手法」もどちらも「分布仮説（単語の意味は周囲の単語によって形成される）」に基づいています。\n",
        "\n",
        "<img width=\"656.25\" alt=\"キャプチャ.PNG (28.8 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/9a178ff1-bf35-4b74-8353-d6b1932513e4.PNG\">\n",
        "\n",
        "## 3.1.1 カウントベース手法の問題点\n",
        "\n",
        "「カウントベースの手法」の問題点としては、コーパス全体の語彙数が膨大（英語の語彙数は100万）になると、その語彙数×語彙数の行列を作る必要があり、$n \\times n$ 行列に $O(n^3)$ の計算量の SVD は、計算量の点で現実的ではありません。\n",
        "\n",
        "例えば、[LAPACK のベンチマーク](http://www.netlib.org/lapack/lug/node71.html) の SVD の計算時間をみると $ n = 100, 1000 $ のケースで下の表のような結果となります（表の古い計算機で $10 \\sim 100$ secオーダーの時間がかかる）。\n",
        "\n",
        "<img width=\"534\" alt=\"キャプチャ.PNG (37.9 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/2b3ac64b-ce4b-415f-a754-81478c922281.PNG\">\n",
        "\n",
        "$n$ の増加に伴い $O(n^3)$ の計算量は下図のように増加していきます（$n=100$ 万の計算量は現実的ではない）。\n",
        "\n",
        "![68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3231353939332f37623966643861302d633765382d343566342d306137622d6633383233356562663838332e6a706567.jpg (149.6 kB)](https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/d05b0ad0-a089-41f8-a77a-9a3254276d2a.jpg)\n",
        "\n",
        "\n",
        "一方、「推論ベースの手法」のモデルの学習で「ニューラルネットワーク」を用いる場合、ミニバッチという形でコーパスの一部を切り取って学習し、その結果から重みを更新していくため、現実的な計算量に制限した計算をGPU等で並列分散処理させつつ繰り返し実施することで、学習モデルの精度を向上させていくことが可能です（下図）。\n",
        "\n",
        "<img width=\"651.75\" alt=\"キャプチャ.PNG (25.7 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/f55ea538-6f24-4910-bcd8-1935ced88601.PNG\">\n",
        "\n",
        "## 3.1.3 ニューラルネットワークにおける単語の処理方法\n",
        "\n",
        "「ニューラルネットワーク」を用いて単語を処理するにあたりそのまま \"you\", \"say\" のような単語をそのまま処理することはできません。\n",
        "\n",
        "そのため「one-hot 表現 or one-hot ベクトル（ベクトルの要素の1つが1で残りが0となるようなベクトル）」を用います。\n",
        "\n",
        "ここでは「you say goodbye and i say hello.」という一文をコーパスとして用います。\n",
        "\n",
        "このコーパスには7個の語彙（\"you\", \"say\", \"goodbye\", \"and\", \"i\", \"hello\", \".\") があります。\n",
        "\n",
        "例えば \"you\", \"goodbye\" の one-hot 表現の例としては下記です。\n",
        "\n",
        "<img width=\"650.25\" alt=\"キャプチャ.PNG (22.4 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/874f0b10-184d-4590-a1ac-65467eb183ce.PNG\">\n",
        "\n",
        "単語をベクトル表現できれば、そのベクトルはニューラルネットワークの「レイヤ」によって処理することができます。\n",
        "\n",
        "ニューラルネットワークの入力層は下記です。\n",
        "\n",
        "<img width=\"650.25\" alt=\"キャプチャ.PNG (55.9 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/fcf412a8-4867-4954-a6b7-6ec357644326.PNG\">\n",
        "\n",
        "全結合層で入力層を変換する場合、例えば下図のように表わせます（ここでは中間層を3つのニューロンとする）。\n",
        "\n",
        "<img width=\"652.5\" alt=\"キャプチャ.PNG (51.9 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/583676a6-306e-4f5f-8d77-9f7e120257d8.PNG\">\n",
        "\n",
        "ちなみに非全結合と全結合は下図で、例えば畳み込みニューラルネットワーク（CNN）では非全結合が用いられます。\n",
        "\n",
        "<img width=\"462.75\" alt=\"キャプチャ.PNG (55.6 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/44f56668-fdd0-4292-8d1c-a3db3387cfe1.PNG\">\n",
        "\n",
        "全結合による変換を数式で表すと、入力層のベクトル $c \\in \\mathbb R^{D}$ に対して、行列 $W \\in \\mathbb R^{d\\times D}$ とバイアスベクトル $b \\in \\mathbb R^{d}$ を用いて\n",
        "\n",
        "$$\n",
        "h = Wc +b\n",
        "$$\n",
        "\n",
        "と表せます。ここでは word2vec の説明を見越して、バイアスは省略し、$b = 0$ とします。\n",
        "\n",
        "すると全結合の変換は単なる行列の積 $h = Wc$ として表せるので、Python としては例えば次のように表現できます。"
      ]
    },
    {
      "metadata": {
        "id": "F6uAb2vL2LzI",
        "colab_type": "code",
        "outputId": "a2163979-bd92-4501-a064-2d8d2e29ae6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "c = np.array([[1,0,0,0,0,0,0]]) #入力\n",
        "W = np.random.randn(7,3) #重み\n",
        "h = np.dot(c, W) #中間層ベクトル\n",
        "print(h)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.93192108  0.16090549 -0.10415464]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DdS6h8Jf23yw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1章で実装した MatMal レイヤを用いると下記のようなコードになります。"
      ]
    },
    {
      "metadata": {
        "id": "yOVKgL0G5UW5",
        "colab_type": "code",
        "outputId": "9a11ad7d-ea1d-44e0-9873-89119cac39d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "from common.layers import MatMul\n",
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
        "W = np.random.randn(7, 3)\n",
        "layer = MatMul(W)\n",
        "h = layer.forward(c)\n",
        "print(h)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.23442125 -1.27825193  0.68147704]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-CvMlaQx3YYw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記計算の注目点としては、$c$ は one-hot 表現のため $Wc$ という行列の積は実質的には、one-hot 表現で 1 が入っている列の番号と同じ番号の W の行を抜き出すことと同じという点です（下図）。\n",
        "\n",
        "<img width=\"652.5\" alt=\"キャプチャ.PNG (47.7 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/08/31597/2634bf25-fde0-4c44-a59e-81e843e9166f.PNG\">\n",
        "\n",
        "# 3.2 word2vec の CBOW(continuous bag-of-words) モデル\n",
        "\n",
        "ここでは「推論ベースの手法」のモデルに「ニューラルネットワーク」を組み込みます。\n",
        "\n",
        "その「ニューラルネットワーク」のモデルとしては word2vec の モデルとしては大きく2つ continuous bag-of-words モデル（以降CBOW）および skip-gram モデル があります。\n",
        "\n",
        "違いとしては下図のように CBOW モデルではコンテクストが複数あり、その複数のコンテクストから中央の単語（「ターゲット」）を推測します。\n",
        "\n",
        "一方 skip-gram モデルでは中央の単語（「ターゲット」）から周囲の複数ある単語（「コンテクスト」）を推測します。\n",
        "\n",
        "<img width=\"652.5\" alt=\"キャプチャ.PNG (23.4 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/09/31597/2eda6be8-ecfc-435e-8480-e0e9a176cc0b.PNG\">\n",
        "\n",
        "ここではまずは CBOW モデルの推論および学習について説明をします。\n",
        "\n",
        "## 3.2.1 CBOW モデルの推論処理\n",
        "\n",
        "CBOW モデルのネットワークは下図です。\n",
        "\n",
        "コンテクスト $ \\bf{h}_1, \\bf{h}_2$ を入力層として、入力層から中間層への変換は重み $ \\bf{W}_i$ を用い、中間層から出力層への変換は重み $ \\bf{W}_o $ を用います。\n",
        "\n",
        "中間層は $\\frac{1}{2} (\\bf{h}_1 + \\bf{h}_2)$ にて求めます。\n",
        "\n",
        "<img width=\"650.25\" alt=\"キャプチャ.PNG (73.2 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/09/31597/adf60223-dbb7-4221-a218-d9580723be43.PNG\">\n",
        "\n",
        "CBOW モデルの推論処理を Python で記述したのが下記です。\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7ed5bjAm631x",
        "colab_type": "code",
        "outputId": "0079e4fb-798d-49e5-eab2-0d3cf1dcda95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "from common.layers import MatMul\n",
        "\n",
        "# サンプルのコンテクストデータ\n",
        "c0 = np.array([[1,0,0,0,0,0,0]])\n",
        "c1 = np.array([[0,0,1,0,0,0,0]])\n",
        "\n",
        "# 重みの初期化\n",
        "W_in = np.random.randn(7,3)\n",
        "W_out = np.random.randn(3,7)\n",
        "\n",
        "# レイヤの生成\n",
        "in_layer0 = MatMul(W_in)\n",
        "in_layer1 = MatMul(W_in)\n",
        "out_layer = MatMul(W_out)\n",
        "\n",
        "# 順伝播\n",
        "h0 = in_layer0.forward(c0)\n",
        "h1 = in_layer1.forward(c1)\n",
        "h = 0.5 * (h0 + h1)\n",
        "s = out_layer.forward(h)\n",
        "\n",
        "print(s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.0936329  -0.40608182 -0.169034    0.16569896 -0.01936698 -0.06109344\n",
            "  -0.18014601]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xEpYc6pyoxP4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2.2 CBOW モデルの学習\n",
        "\n",
        "学習時の CBOW モデルのネットワーク構成は下図です。\n",
        "\n",
        "<img width=\"654\" alt=\"キャプチャ.PNG (33.9 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/09/31597/5d038fde-3aca-4dac-870d-7bac451bd8b2.PNG\">\n",
        "\n",
        "Softmax 関数とは、各ラベルのスコア $s_k$ を用いて下記のように表せます。\n",
        "\n",
        "Softmax 関数を通すと 各ラベルの出力 $y_k$ は 0.0 以上 1.0 以下の値（$k$ 番目のラベルが出現する確率）として出力されます。\n",
        "\n",
        "$$y_k = \\frac{\\exp(s_k)}{\\sum_i \\exp(s_i)}$$\n",
        "\n",
        "交差エントロピー誤差は正解ラベルの one-hot表現されたベクトルの成分 $t_k$ およびSoftmax関数の出力 $y_k$ を用いて以下のように表されます。\n",
        "\n",
        "$$L = -\\sum_k t_k \\log y_k$$\n",
        "\n",
        "CBOW モデルのコンテクストからのターゲットの推測（下図）を確率的に表現すると\n",
        "\n",
        "<img width=\"653.25\" alt=\"キャプチャ.PNG (20.0 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/09/31597/28153b56-b006-481f-8991-bf958d196035.PNG\">\n",
        "\n",
        "$$P(w_t | w_{t-1}, w_{t+1}) $$\n",
        "\n",
        "となります。\n",
        "\n",
        "こちらは「コンテクストとして $w_{t-1}, w_{t+1}$ が与えられた場合にターゲット が $w_t$ となる確率」です。\n",
        "\n",
        "\n",
        "この確率は上記 $y_k$ に対応するもので、交差エントロピー誤差は、one-hot表現では $w_t$ が起こる事象で 1 , それ以外で 0 になることを考慮すると以下になります。\n",
        "\n",
        "$$L = -\\log P(w_t | w_{t-1}, w_{t+1})$$\n",
        "\n",
        "これをコーパス全体に拡張すると次のような交差エントロピー誤差の和として表されます。\n",
        "\n",
        "$$L = -\\frac{1}{T} \\sum_t^T \\log P(w_t | w_{t-1}, w_{t+1})$$\n",
        "\n",
        "word2vec（CBOW, skip-gram）の学習では、入力側の重み $\\bf{W}_i$ を上記の交差エントロピー誤差の和 $L$ を最小にするように最適化していきます（一般的には出力側の重み $\\bf{W}_o$ はあまり用いられないとのこと）。\n",
        "\n",
        "学習ネットワークの構成のポイント：\n",
        "\n",
        "<img width=\"654.75\" alt=\"キャプチャ.PNG (77.5 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/09/31597/ad051386-8ec4-46c7-857a-ac4fc22e2d80.PNG\">\n",
        "\n",
        "# 3.3 学習データの準備\n",
        "\n",
        "## 3.3.1 コンテクストとターゲットおよびそれらの one-hot表現\n",
        "\n",
        "word2vec （CBOW）のニューラルネットワークへの入力は「コンテクスト」です。正解のラベルとしてはコンテクストに囲まれた中央の単語である「ターゲット」です。\n",
        "\n",
        "ニューラルネットワークの学習としては、「コンテクスト」を入力したときに「ターゲット」が出力される\n",
        "\n",
        "\"You say goodbye and I say hello.\" という「コーパス」から「コンテクスト」と「ターゲット」をリスト化したケースが下図です。\n",
        "\n",
        "<img width=\"651.75\" alt=\"キャプチャ.PNG (46.5 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/09/31597/76b96308-0525-435a-8b49-40b2bceba210.PNG\">\n",
        "\n",
        "さらにコンテクストとターゲットを one-hot 表現にする処理の流れを表したのが下図です。\n",
        "\n",
        "<img width=\"655.5\" alt=\"キャプチャ.PNG (49.0 kB)\" src=\"https://img.esa.io/uploads/production/attachments/8793/2019/01/09/31597/08a0ff33-4a6e-44eb-9392-92d7af70f568.PNG\">\n",
        "\n",
        "具体的に Python コードの実装としては下記になります。"
      ]
    },
    {
      "metadata": {
        "id": "8Mn8nho5Bvb8",
        "colab_type": "code",
        "outputId": "b531e5d6-1743-41bb-d258-20e0ab3c43e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "print(corpus)\n",
        "print(word_to_id)\n",
        "print(id_to_word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Hi_vSrcvNFl",
        "colab_type": "code",
        "outputId": "ae2e3a72-2957-49bf-ddba-abae80544423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "contexts, target = create_contexts_target(corpus, window_size=1)\n",
        "\n",
        "print(contexts)\n",
        "print(target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 2]\n",
            " [1 3]\n",
            " [2 4]\n",
            " [3 1]\n",
            " [4 5]\n",
            " [1 6]]\n",
            "[1 2 3 4 1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3BeBRlT4v7GO",
        "colab_type": "code",
        "outputId": "3c5fb42d-3525-4ecb-b811-77558b607fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_id)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "\n",
        "contexts = convert_one_hot(contexts, vocab_size)\n",
        "\n",
        "print(target)\n",
        "print(contexts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0]]\n",
            "[[[1 0 0 0 0 0 0]\n",
            "  [0 0 1 0 0 0 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 1 0 0 0]]\n",
            "\n",
            " [[0 0 1 0 0 0 0]\n",
            "  [0 0 0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 1 0 0 0]\n",
            "  [0 1 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1 0 0]\n",
            "  [0 0 0 0 0 1 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 1]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CW4Pj2AcnGPp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.4 CBOW モデルの実装\n",
        "\n",
        "CBOW モデルの学習コードおよびその実行結果は下記になります。\n",
        "\n",
        "ここでは、ウインドウサイズ 1, 中間層のノードが5つ、バッチサイズ 3, 学習回数1000 としています。\n",
        "\n",
        "学習回数を重ねるごとに損失が減少していることが確認できます。"
      ]
    },
    {
      "metadata": {
        "id": "RdvEwujkxcH_",
        "colab_type": "code",
        "outputId": "f0531199-4c07-4b24-f311-36521b60751c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17361
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.trainer import Trainer\n",
        "from common.optimizer import Adam\n",
        "from ch03.simple_cbow import SimpleCBOW\n",
        "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
        "\n",
        "window_size = 1\n",
        "hidden_size = 5\n",
        "batch_size = 3\n",
        "max_epoch = 1000\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "contexts, target = create_contexts_target(corpus, window_size)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)\n",
        "\n",
        "model = SimpleCBOW(vocab_size, hidden_size)\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "trainer.fit(contexts, target, max_epoch, batch_size)\n",
        "trainer.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch 1 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 2 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 3 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 4 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 5 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 6 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 7 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 8 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 9 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 10 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 11 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 12 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 13 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 14 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 15 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 16 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 17 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 18 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 19 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 20 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 21 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 22 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 23 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 24 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 25 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 26 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 27 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 28 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 29 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 30 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 31 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 32 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 33 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 34 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 35 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 36 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 37 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 38 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 39 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 40 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 41 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 42 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 43 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 44 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 45 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 46 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 47 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 48 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 49 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 50 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 51 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 52 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 53 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 54 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 55 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 56 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 57 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 58 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 59 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 60 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 61 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 62 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 63 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 64 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 65 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 66 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 67 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 68 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 69 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 70 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 71 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 72 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 73 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 74 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 75 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 76 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 77 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 78 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 79 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 80 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 81 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 82 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 83 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 84 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
            "| epoch 85 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 86 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
            "| epoch 87 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
            "| epoch 88 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 89 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
            "| epoch 90 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 91 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 92 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 93 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 94 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
            "| epoch 95 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 96 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 97 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
            "| epoch 98 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 99 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 100 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 101 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 102 |  iter 1 / 2 | time 0[s] | loss 1.74\n",
            "| epoch 103 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
            "| epoch 104 |  iter 1 / 2 | time 0[s] | loss 1.74\n",
            "| epoch 105 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
            "| epoch 106 |  iter 1 / 2 | time 0[s] | loss 1.69\n",
            "| epoch 107 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
            "| epoch 108 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 109 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 110 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 111 |  iter 1 / 2 | time 0[s] | loss 1.70\n",
            "| epoch 112 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 113 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
            "| epoch 114 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 115 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 116 |  iter 1 / 2 | time 0[s] | loss 1.66\n",
            "| epoch 117 |  iter 1 / 2 | time 0[s] | loss 1.67\n",
            "| epoch 118 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
            "| epoch 119 |  iter 1 / 2 | time 0[s] | loss 1.67\n",
            "| epoch 120 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 121 |  iter 1 / 2 | time 0[s] | loss 1.69\n",
            "| epoch 122 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
            "| epoch 123 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
            "| epoch 124 |  iter 1 / 2 | time 0[s] | loss 1.62\n",
            "| epoch 125 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
            "| epoch 126 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 127 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 128 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
            "| epoch 129 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
            "| epoch 130 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
            "| epoch 131 |  iter 1 / 2 | time 0[s] | loss 1.55\n",
            "| epoch 132 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
            "| epoch 133 |  iter 1 / 2 | time 0[s] | loss 1.60\n",
            "| epoch 134 |  iter 1 / 2 | time 0[s] | loss 1.59\n",
            "| epoch 135 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 136 |  iter 1 / 2 | time 0[s] | loss 1.62\n",
            "| epoch 137 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
            "| epoch 138 |  iter 1 / 2 | time 0[s] | loss 1.60\n",
            "| epoch 139 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
            "| epoch 140 |  iter 1 / 2 | time 0[s] | loss 1.60\n",
            "| epoch 141 |  iter 1 / 2 | time 0[s] | loss 1.56\n",
            "| epoch 142 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 143 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 144 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 145 |  iter 1 / 2 | time 0[s] | loss 1.55\n",
            "| epoch 146 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
            "| epoch 147 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
            "| epoch 148 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 149 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 150 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 151 |  iter 1 / 2 | time 0[s] | loss 1.56\n",
            "| epoch 152 |  iter 1 / 2 | time 0[s] | loss 1.45\n",
            "| epoch 153 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 154 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
            "| epoch 155 |  iter 1 / 2 | time 0[s] | loss 1.45\n",
            "| epoch 156 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
            "| epoch 157 |  iter 1 / 2 | time 0[s] | loss 1.45\n",
            "| epoch 158 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 159 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 160 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 161 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 162 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 163 |  iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 164 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 165 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 166 |  iter 1 / 2 | time 0[s] | loss 1.37\n",
            "| epoch 167 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 168 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
            "| epoch 169 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
            "| epoch 170 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 171 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 172 |  iter 1 / 2 | time 0[s] | loss 1.37\n",
            "| epoch 173 |  iter 1 / 2 | time 0[s] | loss 1.38\n",
            "| epoch 174 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 175 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 176 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 177 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
            "| epoch 178 |  iter 1 / 2 | time 0[s] | loss 1.37\n",
            "| epoch 179 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 180 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
            "| epoch 181 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
            "| epoch 182 |  iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 183 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
            "| epoch 184 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 185 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 186 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
            "| epoch 187 |  iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 188 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
            "| epoch 189 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
            "| epoch 190 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 191 |  iter 1 / 2 | time 0[s] | loss 1.34\n",
            "| epoch 192 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
            "| epoch 193 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 194 |  iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 195 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
            "| epoch 196 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 197 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
            "| epoch 198 |  iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 199 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 200 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 201 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 202 |  iter 1 / 2 | time 0[s] | loss 1.27\n",
            "| epoch 203 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 204 |  iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 205 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 206 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 207 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 208 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 209 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 210 |  iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 211 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
            "| epoch 212 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 213 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 214 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 215 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 216 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 217 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 218 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 219 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 220 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 221 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 222 |  iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 223 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 224 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
            "| epoch 225 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 226 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 227 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
            "| epoch 228 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 229 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 230 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 231 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
            "| epoch 232 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 233 |  iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 234 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 235 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 236 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 237 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 238 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 239 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 240 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 241 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 242 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 243 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 244 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 245 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 246 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 247 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 248 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 249 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 250 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 251 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 252 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 253 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 254 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 255 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 256 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 257 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 258 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 259 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 260 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 261 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 262 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 263 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 264 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 265 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 266 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 267 |  iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 268 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 269 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 270 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 271 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 272 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 273 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 274 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 275 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 276 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 277 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 278 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 279 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 280 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 281 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 282 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 283 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 284 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 285 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 286 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 287 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 288 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 289 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 290 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 291 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 292 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 293 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 294 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 295 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 296 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 297 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 298 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 299 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 300 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 301 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 302 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 303 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 304 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 305 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 306 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 307 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 308 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 309 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 310 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 311 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 312 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 313 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 314 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 315 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 316 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 317 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 318 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 319 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 320 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 321 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 322 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 323 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 324 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 325 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 326 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 327 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 328 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 329 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 330 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 331 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 332 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 333 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 334 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 335 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 336 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 337 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 338 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 339 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 340 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 341 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 342 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 343 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 344 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 345 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 346 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 347 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 348 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 349 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 350 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 351 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 352 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 353 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 354 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 355 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 356 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 357 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 358 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 359 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 360 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 361 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 362 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 363 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 364 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 365 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 366 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 367 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 368 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 369 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 370 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 371 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 372 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 373 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 374 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 375 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 376 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 377 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 378 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 379 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 380 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 381 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 382 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 383 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 384 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 385 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 386 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 387 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 388 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 389 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 390 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 391 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 392 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 393 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 394 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 395 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 396 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 397 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 398 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 399 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 400 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 401 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 402 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 403 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 404 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 405 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 406 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 407 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 408 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 409 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 410 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 411 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 412 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 413 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 414 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 415 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 416 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 417 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 418 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 419 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 420 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 421 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 422 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 423 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 424 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 425 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 426 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 427 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 428 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 429 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 430 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 431 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 432 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 433 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 434 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 435 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 436 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 437 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 438 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 439 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 440 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 441 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 442 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 443 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 444 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 445 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 446 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 447 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 448 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 449 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 450 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 451 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 452 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 453 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 454 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 455 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 456 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 457 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 458 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 459 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 460 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 461 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 462 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 463 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 464 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 465 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 466 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 467 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 468 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 469 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 470 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 471 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 472 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 473 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 474 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 475 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 476 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 477 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 478 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 479 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 480 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 481 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 482 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 483 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 484 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 485 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 486 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 487 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 488 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 489 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 490 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 491 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 492 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 493 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 494 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 495 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 496 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 497 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 498 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 499 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 500 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 501 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 502 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 503 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 504 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 505 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 506 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 507 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 508 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 509 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 510 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 511 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 512 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 513 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 514 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 515 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 516 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 517 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 518 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 519 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 520 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 521 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 522 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 523 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 524 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 525 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 526 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 527 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 528 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 529 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 530 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 531 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 532 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 533 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 534 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 535 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 536 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 537 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 538 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 539 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 540 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 541 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 542 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 543 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 544 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 545 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 546 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 547 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 548 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 549 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 550 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 551 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 552 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 553 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 554 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 555 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 556 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 557 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 558 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 559 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 560 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 561 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 562 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 563 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 564 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 565 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 566 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 567 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 568 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 569 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 570 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 571 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 572 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 573 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 574 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 575 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 576 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 577 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 578 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 579 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 580 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 581 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 582 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 583 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 584 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 585 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 586 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 587 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 588 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 589 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 590 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 591 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 592 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 593 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 594 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 595 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 596 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 597 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 598 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 599 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 600 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 601 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 602 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 603 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 604 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 605 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 606 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 607 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 608 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 609 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 610 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 611 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 612 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 613 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 614 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 615 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 616 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 617 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 618 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 619 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 620 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 621 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 622 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 623 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 624 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 625 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 626 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 627 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 628 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 629 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 630 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 631 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 632 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 633 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 634 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 635 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 636 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 637 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 638 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 639 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 640 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 641 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 642 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 643 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 644 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 645 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 646 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 647 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 648 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 649 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 650 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 651 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 652 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 653 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 654 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 655 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 656 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 657 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 658 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 659 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 660 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 661 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 662 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 663 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 664 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 665 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 666 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 667 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
            "| epoch 668 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 669 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 670 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 671 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 672 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 673 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 674 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 675 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 676 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 677 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 678 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 679 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 680 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 681 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 682 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 683 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 684 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 685 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 686 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 687 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 688 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 689 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 690 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 691 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 692 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 693 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 694 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 695 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 696 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 697 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 698 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 699 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 700 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 701 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 702 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 703 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 704 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 705 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 706 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 707 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 708 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 709 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 710 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 711 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 712 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 713 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 714 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 715 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 716 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 717 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 718 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 719 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 720 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 721 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 722 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 723 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 724 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 725 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 726 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 727 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 728 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 729 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 730 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 731 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 732 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 733 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 734 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 735 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 736 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 737 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 738 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 739 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
            "| epoch 740 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 741 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 742 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 743 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 744 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 745 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 746 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 747 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 748 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 749 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 750 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 751 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 752 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 753 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 754 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 755 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 756 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 757 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 758 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 759 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 760 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 761 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 762 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 763 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 764 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 765 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 766 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 767 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 768 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 769 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 770 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 771 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 772 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 773 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 774 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 775 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 776 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 777 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 778 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 779 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 780 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 781 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 782 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 783 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 784 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 785 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 786 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 787 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 788 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 789 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 790 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 791 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 792 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 793 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 794 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 795 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 796 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 797 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 798 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 799 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 800 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 801 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 802 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 803 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 804 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 805 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 806 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 807 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 808 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 809 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 810 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 811 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 812 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 813 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 814 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 815 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 816 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 817 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 818 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 819 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 820 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 821 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 822 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 823 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 824 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 825 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 826 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 827 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 828 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 829 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 830 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 831 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 832 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 833 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 834 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 835 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 836 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 837 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 838 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 839 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 840 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 841 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 842 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 843 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 844 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 845 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 846 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 847 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 848 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 849 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 850 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 851 |  iter 1 / 2 | time 0[s] | loss 0.23\n",
            "| epoch 852 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 853 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 854 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 855 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 856 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 857 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 858 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 859 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 860 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 861 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 862 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 863 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 864 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 865 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 866 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 867 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 868 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 869 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 870 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 871 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 872 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 873 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 874 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 875 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 876 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 877 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 878 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 879 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 880 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 881 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 882 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 883 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 884 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 885 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 886 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 887 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 888 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 889 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 890 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 891 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 892 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 893 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 894 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 895 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 896 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 897 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 898 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 899 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 900 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 901 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 902 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 903 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 904 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 905 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 906 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 907 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 908 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 909 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 910 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 911 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 912 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 913 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
            "| epoch 914 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 915 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 916 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 917 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 918 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 919 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 920 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
            "| epoch 921 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 922 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 923 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 924 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 925 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 926 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 927 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 928 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 929 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 930 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 931 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 932 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 933 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 934 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 935 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 936 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 937 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 938 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 939 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 940 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 941 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 942 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 943 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 944 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 945 |  iter 1 / 2 | time 0[s] | loss 0.27\n",
            "| epoch 946 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 947 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 948 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
            "| epoch 949 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 950 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 951 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 952 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 953 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 954 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 955 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 956 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 957 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 958 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 959 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 960 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 961 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 962 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 963 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 964 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 965 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 966 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 967 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 968 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 969 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 970 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 971 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 972 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 973 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 974 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 975 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 976 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 977 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 978 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 979 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 980 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 981 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 982 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 983 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 984 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 985 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 986 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 987 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 988 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 989 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 990 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 991 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 992 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 993 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 994 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 995 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 996 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 997 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 998 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 999 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 1000 |  iter 1 / 2 | time 0[s] | loss 0.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ1ZAkYwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f88b94531d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_5YylBmlqIU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "入力層の重み$\\bf{W}_i$ は word_vecs というメンバ変数に格納されています。\n",
        "\n",
        "word_vecs の各行に対応する単語ID の分散表現が格納されています。"
      ]
    },
    {
      "metadata": {
        "id": "SaoBsQfzOkjY",
        "colab_type": "code",
        "outputId": "1df9419d-ffd9-418c-9014-b692ef303eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "word_vecs = model.word_vecs\n",
        "for word_id, word in id_to_word.items():\n",
        "  print(word, word_vecs[word_id])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you [-1.0774181  -0.41502443 -1.3285251   1.3598249   1.2219367 ]\n",
            "say [ 1.2927059  -1.2872394   0.41435072 -0.01135265 -0.44694942]\n",
            "goodbye [-0.8319485   1.4571052  -0.62633795  0.5318103   0.67397696]\n",
            "and [ 1.129695  -1.1180661  1.3881688  1.4450581  1.6253179]\n",
            "i [-0.79824674  1.4709252  -0.61878735  0.50901085  0.6567813 ]\n",
            "hello [-1.0821677  -0.40568072 -1.347526    1.3584945   1.2378774 ]\n",
            ". [ 1.0816252 -1.0866023 -1.4564561 -1.2368044 -1.2329001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Je2xAjyIxD46",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "本来であればこちらの分散表現が「単語の意味」を上手く捉えたベクトル表現となっていることが期待されますが、残念ながら今回扱ったコーパスのサイズが小さいため、良い結果は得られてないです。\n",
        "\n",
        "もちろん、コーパスサイズを大きくすれば良い結果が期待されますが、今回実装した CBOW モデルでは処理速度の点で問題があります。\n",
        "\n",
        "次章以降で処理速度の問題を解決する「本物」の CBOW モデルの実装をおこなっていきます。"
      ]
    },
    {
      "metadata": {
        "id": "Ok1P6s6vrqzI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## （応用）夏目漱石の「こころ」を word2vec で学習される方法\n",
        "\n",
        "アドバンスな題材として、コーパスサイズを大きくした場合を検討してみます。\n",
        "\n",
        "ここでは、青空文庫にある夏目漱石の「こころ」を word2vec で学習させて、「先生」という単語に関連の深い単語を列挙してみましょう（[参考](https://qiita.com/makaishi2/items/63b7986f6da93dc55edd)）\n",
        "\n",
        "具体的なコードおよび実行結果としては下記です。"
      ]
    },
    {
      "metadata": {
        "id": "SPLpwcRASAGX",
        "colab_type": "code",
        "outputId": "bbdf9a02-0b94-44d9-c5c2-a6a4144f44bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "# 夏目漱石「こころ」のファイルダウンロード、解凍\n",
        "!wget https://www.aozora.gr.jp/cards/000148/files/773_ruby_5968.zip\n",
        "!unzip 773_ruby_5968.zip\n",
        "!ls -l kokoro.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-09 03:04:13--  https://www.aozora.gr.jp/cards/000148/files/773_ruby_5968.zip\n",
            "Resolving www.aozora.gr.jp (www.aozora.gr.jp)... 59.106.13.115\n",
            "Connecting to www.aozora.gr.jp (www.aozora.gr.jp)|59.106.13.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 153688 (150K) [application/zip]\n",
            "Saving to: ‘773_ruby_5968.zip’\n",
            "\n",
            "773_ruby_5968.zip   100%[===================>] 150.09K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-01-09 03:04:18 (12.1 MB/s) - ‘773_ruby_5968.zip’ saved [153688/153688]\n",
            "\n",
            "Archive:  773_ruby_5968.zip\n",
            "Made with MacWinZipper™\n",
            "  inflating: kokoro.txt              \n",
            "-rw-r--r-- 1 root root 374152 Oct 31  2010 kokoro.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ieqdq_6Ne15C",
        "colab_type": "code",
        "outputId": "51aa82f2-ecf9-4622-c9ae-70bb681ceb1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "# ファイル読込み、内部表現化\n",
        "f = codecs.open('kokoro.txt', \"r\", \"sjis\")\n",
        "text = f.read()\n",
        "f.close()\n",
        "\n",
        "# ファイル整形\n",
        "import re\n",
        "# ヘッダ部分の除去\n",
        "text = re.split('\\-{5,}',text)[2]\n",
        "# フッタ部分の除去\n",
        "text = re.split('底本：',text)[0]\n",
        "# | の除去\n",
        "text = text.replace('|', '')\n",
        "# ルビの削除\n",
        "text = re.sub('《.+?》', '', text)\n",
        "# 入力注の削除\n",
        "text = re.sub('［＃.+?］', '',text)\n",
        "# 空行の削除\n",
        "text = re.sub('\\n\\n', '\\n', text) \n",
        "text = re.sub('\\r', '', text)\n",
        "\n",
        "# 整形結果確認\n",
        "\n",
        "# 頭の100文字の表示 \n",
        "print(text[:100])\n",
        "# 見やすくするため、空行 \n",
        "print()\n",
        "print()\n",
        "# 後ろの100文字の表示 \n",
        "print(text[-100:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "上　先生と私\n",
            "\n",
            "\n",
            "一\n",
            "\n",
            "　私はその人を常に先生と呼んでいた。だからここでもただ先生と書くだけで本名は打ち明けない。これは世間を憚かる遠慮というよりも、その方が私にとって自然だからである。私はその人\n",
            "\n",
            "\n",
            "、なるべく純白に保存しておいてやりたいのが私の唯一の希望なのですから、私が死んだ後でも、妻が生きている以上は、あなた限りに打ち明けられた私の秘密として、すべてを腹の中にしまっておいて下さい。」\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzo0nYamfAd4",
        "colab_type": "code",
        "outputId": "b69446bf-09e8-47a1-ac6d-782fb188ac03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "# Janomeのインストール\n",
        "!pip install janome\n",
        "\n",
        "# Janomeのロード\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "# Tokenneizerインスタンスの生成 \n",
        "t = Tokenizer()\n",
        "\n",
        "# テキストを引数として、形態素解析の結果、名詞・動詞原型のみを配列で抽出する関数を定義 \n",
        "def extract_words(text):\n",
        "    tokens = t.tokenize(text)\n",
        "    return [token.base_form for token in tokens \n",
        "        if token.part_of_speech.split(',')[0] in['名詞', '動詞']]\n",
        "\n",
        "#  関数テスト\n",
        "ret = extract_words('精神的に向上心がないものは馬鹿だといって、何だか私をさも軽薄もののようにやり込めるのです。')\n",
        "for word in ret:\n",
        "    print(word)\n",
        "\n",
        "# 全体のテキストを句点('。')で区切った配列にする。 \n",
        "sentences = text.split('。')\n",
        "# それぞれの文章を単語リストに変換(処理に数分かかります)\n",
        "word_list = [extract_words(sentence) for sentence in sentences]\n",
        "\n",
        "# 結果の一部を確認 \n",
        "for word in word_list[0]:\n",
        "    print(word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: janome in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "精神\n",
            "的\n",
            "向上心\n",
            "もの\n",
            "馬鹿\n",
            "いう\n",
            "私\n",
            "薄もの\n",
            "よう\n",
            "やり込める\n",
            "の\n",
            "上\n",
            "先生\n",
            "私\n",
            "一\n",
            "私\n",
            "人\n",
            "先生\n",
            "呼ぶ\n",
            "いる\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U_bru1EWfFgc",
        "colab_type": "code",
        "outputId": "8430c739-0f80-4b1f-d830-c108570dfc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "# Word2Vecライブラリの導入\n",
        "!pip install gensim  \n",
        "\n",
        "# Word2Vecライブラリのロード\n",
        "from gensim.models import word2vec\n",
        "\n",
        "# size: 圧縮次元数\n",
        "# min_count: 出現頻度の低いものをカットする\n",
        "# window: 前後の単語を拾う際の窓の広さを決める\n",
        "# iter: 機械学習の繰り返し回数(デフォルト:5)十分学習できていないときにこの値を調整する\n",
        "# model.wv.most_similarの結果が1に近いものばかりで、model.dict['wv']のベクトル値が小さい値ばかりの \n",
        "# ときは、学習回数が少ないと考えられます。\n",
        "# その場合、iterの値を大きくして、再度学習を行います。\n",
        "\n",
        "# 事前準備したword_listを使ってWord2Vecの学習実施\n",
        "model = word2vec.Word2Vec(word_list, size=50,min_count=5,window=5,iter=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.72)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.72 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.72)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.72->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.72->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0WLjaycGfXgx",
        "colab_type": "code",
        "outputId": "85f27f05-8e16-4ab9-e405-cc18c67e580d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "# 結果の確認1\n",
        "# 一つ一つの単語は100次元のベクトルになっています。 \n",
        "# 「先生」のベクトル値を確認します。\n",
        "print(model.__dict__['wv']['先生'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.6569985  -0.11994954 -0.6427742   1.213398   -1.8398448   1.1827036\n",
            "  0.4986367   0.04548284  2.44457     1.4014504  -0.9706929  -0.66404366\n",
            " -1.4268262   0.06282885  1.6198504  -1.1201216  -0.17802139  0.29679334\n",
            " -0.27737296  0.4717287  -0.7174956  -2.2708552  -0.28564936 -1.7458433\n",
            " -0.10778152 -0.30328184  0.48663938  1.4171972  -0.8220578   0.22087117\n",
            "  0.7119671   1.7111647  -0.5076243   0.821836   -0.42733327  1.0684468\n",
            " -0.8721215  -0.70046467 -1.2951814   0.60690194  0.46786955  0.3648031\n",
            " -1.6260331   1.2887772  -0.27446723 -1.2381439   0.31714582  0.08626555\n",
            " -0.5637      0.30560726]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bHXgm2BLfhvD",
        "colab_type": "code",
        "outputId": "2a828b22-c950-48c5-e76e-8f66449e9dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "# 結果の確認2\n",
        "# 関数most_similarを使って「先生」の類似単語を調べます \n",
        "ret = model.wv.most_similar(positive=['先生']) \n",
        "for item in ret:\n",
        "    print(item[0], item[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "奥さん 0.523717999458313\n",
            "私 0.5059327483177185\n",
            "あなた 0.43613502383232117\n",
            "時 0.3846054673194885\n",
            "する 0.36490634083747864\n",
            "食卓 0.35665929317474365\n",
            "財産 0.34628137946128845\n",
            "式 0.3399178683757782\n",
            "いう 0.3294997811317444\n",
            "出す 0.32745128870010376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JmGiOiCzs1Y_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.5.3 カウントベース vs 推論ベース\n",
        "\n",
        "本章の最初に学習される計算量の面で推論ベースの手法のメリットを挙げました。\n",
        "\n",
        "それではカウントベースと推論ベースの2つの手法の分散表現の性質や精度についてはどうでしょうか？\n",
        "\n",
        "分散表現の性質という点では、カウントベースの手法では単語どうしの類似性をエンコードすることができますが、類推ベースの手法では単語どうしの類似性のみならず単語間のパターンも捉えられる（「king - man + woman = queen」のような類推問題が解ける）ことが分かっています。\n",
        "\n",
        "精度という点では、類推ベースの手法がカウントベースの手法に比べて精度が優れているという誤解もありますが、実際は2つの手法には優劣がつけられないことがいくつかの論文で報告されています。\n",
        "\n",
        "* \"[Improving distributional similarity with lessons learned from word embeddings.](http://www.aclweb.org/anthology/Q15-1016)\"\n",
        "\n",
        "* \"[Neural word embedding as implicit matrix factorization.](https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf)\"\n",
        "\n"
      ]
    }
  ]
}